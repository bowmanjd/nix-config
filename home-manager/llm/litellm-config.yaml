copilot_default: &copilot_default copilot-gpt-4.1

common_copilot: &common_copilot
  api_base: https://api.githubcopilot.com
  api_key: "os.environ/COPILOT_API_KEY" 
  rpm: 20
  input_cost_per_token: 0.0
  output_cost_per_token: 0.0
  extra_headers:
    Copilot-Integration-Id: vscode-chat
    Editor-Version: neovim/0.11.1

copilot_base: &copilot_base
  model: openai/gpt-4.1
  max_tokens: 128000
  max_output_tokens: 16384
  max_input_tokens: 128000
  <<: *common_copilot

qwen_params: &qwen_params
  temperature: 0.7
  top_p: 0.8
  top_k: 20
  min_p: 0

model_list:
  # - model_name: openai/*
  #   litellm_params:
  #     model: openai/*
  # - model_name: openrouter/*
  #   litellm_params:
  #     model: openrouter/*
  # - model_name: anthropic/*
  #   litellm_params:
  #     model: anthropic/*
  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash-preview-05-20
      weight: 10
    model_info:
      id: gemini-2.5-flash
  - model_name: gemini-2.5-flash
    litellm_params:
      model: openrouter/gemini/gemini-2.5-flash-preview-05-20
      weight: 1
    model_info:
      id: openrouter-gemini-2.5-flash
  - model_name: gemma-3
    litellm_params:
      model: gemini/gemma-3-27b-it
      max_output_tokens: 8192
      max_input_tokens: 128000
      weight: 10
    model_info:
      id: gemma-3:27b
  - model_name: gemma-3
    litellm_params:
      model: openrouter/google/gemma-3-27b-it:free
      max_output_tokens: 8192
      max_input_tokens: 128000
      weight: 10
    model_info:
      id: openrouter-gemma-3:27b
  - model_name: gemma-3
    litellm_params:
      model: cloudflare/@cf/google/gemma-3-12b-it
      max_output_tokens: 8192
      max_input_tokens: 128000
      weight: 3
    model_info:
      id: cf-gemma-3:12b
  - model_name: gemma-3
    litellm_params:
      model: ollama_chat/gemma3:4b 
      api_base: http://localhost:11434
      max_output_tokens: 8192
      max_input_tokens: 128000
      weight: 1
    model_info:
      id: local-gemma-3:4b
  - model_name: gemma-3
    litellm_params:
      model: ollama_chat/hf.co/mradermacher/gemma-3-4b-it-i1-GGUF:Q4_K_S
      api_base: http://10.0.0.10:11434
      max_output_tokens: 8192
      max_input_tokens: 128000
      weight: 1
    model_info:
      id: boron-gemma-3:4b
  - model_name: gemma-3n
    litellm_params:
      model: gemini/gemma-3n-e4b-it
      max_output_tokens: 32768
      max_input_tokens: 32768
      weight: 10
  - model_name: gemma-3n
    litellm_params:
      model: openrouter/google/gemma-3n-e4b-it:free
      max_output_tokens: 32768
      max_input_tokens: 32768
  - model_name: llama-4-scout
    litellm_params:
      model: groq/meta-llama/llama-4-scout-17b-16e-instruct
  - model_name: llama-4-scout
    litellm_params:
      model: cerebras/llama-4-scout-17b-16e-instruct
  - model_name: llama-4-scout
    litellm_params:
      model: cloudflare/@cf/meta/llama-4-scout-17b-16e-instruct
  - model_name: llama-4-scout
    litellm_params:
      model: openrouter/meta-llama/llama-4-scout:free
  - model_name: llama-4-maverick
    litellm_params:
      model: groq/meta-llama/llama-4-maverick-17b-128e-instruct
  - model_name: llama-4-maverick
    litellm_params:
      model: openrouter/llama-4-maverick:free
  - model_name: deepseek-r1-70b
    litellm_params:
      model: groq/deepseek-r1-distill-llama-70b
  - model_name: deepseek-r1-70b
    litellm_params:
      model: together_ai/deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free
  - model_name: codestral
    litellm_params:
      model: codestral/codestral-2501
  - model_name: codestral
    litellm_params:
      model: mistral/codestral-2501
  - model_name: mistral-medium
    litellm_params:
      model: mistral/mistral-medium-2505
  - model_name: mistral-small
    litellm_params:
      model: mistral/mistral-small-2503
  - model_name: mistral-small
    litellm_params:
      model: cloudflare/@cf/mistralai/mistral-small-3.1-24b-instruct
  - model_name: mistral-small
    litellm_params:
      model: openrouter/mistralai/mistral-small-3.1-24b-instruct:free
  - model_name: deepseek-r1
    litellm_params:
      model: openrouter/deepseek/deepseek-r1-0528
      temperature: 0.6
      top_p: 0.95
  - model_name: deepseek-r1-qwen3-8b
    litellm_params:
      model: openrouter/deepseek/deepseek-r1-0528-qwen3-8b:free
      temperature: 0.6
      top_p: 0.95
  - model_name: devstral
    litellm_params:
      model: mistral/devstral-small-2505
      weight: 10
  - model_name: devstral
    litellm_params:
      model: openrouter/mistralai/devstral-small:free
      weight: 5
  - model_name: devstral
    litellm_params:
      model: openrouter/mistralai/devstral-small:nitro
      weight: 3
  - model_name: devstral
    litellm_params:
      model: ollama_chat/devstral
      api_base: http://localhost:11434
      weight: 1
  - model_name: llama-3.3
    litellm_params:
      model: cloudflare/@cf/meta/llama-3.3-70b-instruct-fp8-fast
  - model_name: llama-3.3
    litellm_params:
      model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free
  - model_name: llama-3.3
    litellm_params:
      model: groq/llama-3.3-70b-versatile
  - model_name: llama-3.3
    litellm_params:
      model: cerebras/llama-3.3-70b
  - model_name: llama-3.3
    litellm_params:
      model: openrouter/meta-llama/llama-3.3-70b-instruct:free
  - model_name: claude-4-sonnet
    litellm_params:
      model: openai/claude-sonnet-4
      max_tokens: 80000
      max_output_tokens: 16000
      max_input_tokens: 80000
      weight: 20
      <<: *common_copilot
  - model_name: claude-4-sonnet
    litellm_params:
      model: openrouter/anthropic/claude-4-sonnet
      weight: 3
    model_info:
      id: openrouter-claude-3.7-sonnet
  - model_name: claude-4-sonnet
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      weight: 1
    model_info:
      id: anthropic-claude-4-sonnet
  - model_name: claude-3.7-sonnet
    litellm_params:
      model: openai/claude-3.7-sonnet
      max_tokens: 200000
      max_output_tokens: 16384
      max_input_tokens: 90000
      weight: 20
      <<: *common_copilot
    model_info:
      id: copilot-claude-3.7-sonnet
  - model_name: claude-3.7-sonnet
    litellm_params:
      model: openrouter/anthropic/claude-3.7-sonnet
      weight: 3
    model_info:
      id: openrouter-claude-3.7-sonnet
  - model_name: claude-3.7-sonnet
    litellm_params:
      model: anthropic/claude-3.7-sonnet-latest
      weight: 1
    model_info:
      id: anthropic-claude-3.7-sonnet
  - model_name: claude-3.5-sonnet
    litellm_params:
      model: openai/claude-3.5-sonnet
      max_tokens: 90000
      max_output_tokens: 8192
      max_input_tokens: 90000
      <<: *common_copilot
  - model_name: gemini-2.0-flash
    litellm_params:
      model: openai/gemini-2.0-flash-001
      max_tokens: 1000000
      max_output_tokens: 8192
      max_input_tokens: 128000
      <<: *common_copilot
      weight: 20
  - model_name: gemini-pro
    litellm_params:
      model: openai/gemini-2.5-pro
      max_tokens: 128000
      max_output_tokens: 64000
      max_input_tokens: 128000
      <<: *common_copilot
      weight: 10
    model_info:
      id: copilot-gemini-pro
  - model_name: gemini-pro
    litellm_params:
      model: openrouter/google/gemini-2.5-pro-preview
      weight: 1
    model_info:
      id: openrouter-gemini-pro
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      max_tokens: 128000
      max_output_tokens: 4096
      max_input_tokens: 64000
      weight: 20
      <<: *common_copilot
  - model_name: o1
    litellm_params:
      model: openai/o1
      max_tokens: 200000
      max_input_tokens: 20000
      weight: 20
      <<: *common_copilot
  - model_name: o3-mini
    litellm_params:
      model: openai/o3-mini
      max_tokens: 200000
      max_output_tokens: 100000
      max_input_tokens: 64000
      weight: 20
      <<: *common_copilot
  - model_name: o4-mini
    litellm_params:
      model: openai/o4-mini
      max_tokens: 128000
      max_output_tokens: 16384
      max_input_tokens: 128000
      weight: 20
      <<: *common_copilot
  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      # max_tokens: 128000
      # max_output_tokens: 8192
      # max_input_tokens: 64000
      weight: 20
      <<: *common_copilot
    model_info:
      id: copilot-gpt-4.1
  - model_name: gpt-4.1
    litellm_params:
      model: openrouter/openai/gpt-4.1
      weight: 2
      input_cost_per_token: 2e-06
      output_cost_per_token: 8e-06
    model_info:
      id: openrouter-gpt-4.1
  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      weight: 1
      input_cost_per_token: 2e-06
      output_cost_per_token: 8e-06
    model_info:
      id: openai-gpt-4.1
  - model_name: boron-phi
    litellm_params:
      model: ollama_chat/hf.co/bartowski/microsoft_Phi-4-mini-instruct-GGUF:IQ4_XS
      api_base: http://10.0.0.10:11434
  - model_name: boron-qwen
    litellm_params:
      model: ollama_chat/hf.co/bartowski/Qwen_Qwen3-4B-GGUF:IQ4_XS
      api_base: http://10.0.0.10:11434
      <<: *qwen_params
  - model_name: boron-code-embedding
    litellm_params:
      model: ollama/hf.co/gaianet/jina-embeddings-v2-base-code-GGUF:Q5_K_M
      api_base: http://10.0.0.10:11434
  - model_name: boron-embedding
    litellm_params:
      model: ollama/granite-embedding:30m
      api_base: http://10.0.0.10:11434
  - model_name: local-code-embedding
    litellm_params:
      model: ollama/hf.co/gaianet/jina-embeddings-v2-base-code-GGUF:Q5_K_M
      api_base: http://localhost:11434
  - model_name: qwen3-embedding
    litellm_params:
      model: ollama/hf.co/Qwen/Qwen3-Embedding-0.6B-GGUF:Q8_0
      api_base: http://localhost:11434
  - model_name: local-embedding
    litellm_params:
      model: ollama/granite-embedding:30m
      api_base: http://localhost:11434
  - model_name: homecode
    litellm_params:
      <<: *copilot_base
  - model_name: qwen3
    litellm_params:
      model: openrouter/qwen/qwen3-32b:free
      <<: *qwen_params
      weight: 20
      extra_body:
        reasoning:
          exclude: true
    model_info:
      id: openrouter-qwen-3-32b:free
  - model_name: qwen3
    litellm_params:
      model: cerebras/qwen-3-32b
      weight: 15
      <<: *qwen_params
    model_info:
      id: cerebras-qwen-3-32b
  - model_name: qwen3
    litellm_params:
      model: openrouter/qwen/qwen3-32b
      weight: 1
      <<: *qwen_params
      extra_body:
        reasoning:
          exclude: true
    model_info:
      id: openrouter-qwen-3-32b
  - model_name: qwen3:8b
    litellm_params:
      model: ollama_chat/qwen3:8b
      api_base: http://localhost:11434
      <<: *qwen_params
    model_info:
      id: local-qwen-3:8b
  - model_name: qwen3big
    litellm_params:
      model: openrouter/qwen/qwen3-235b-a22b:free
      <<: *qwen_params
      weight: 10
      extra_body:
        reasoning:
          exclude: true
    model_info:
      id: openrouter-qwen-3-235b:free
  - model_name: qwen3big
    litellm_params:
      model: openrouter/qwen/qwen3-235b-a22b
      <<: *qwen_params
      weight: 1
      extra_body:
        reasoning:
          exclude: true
    model_info:
      id: openrouter-qwen-3-235b
  - model_name: qwen3bigthink
    litellm_params:
      model: openrouter/qwen/qwen3-235b-a22b:free
      <<: *qwen_params
    model_info:
      id: openrouter-qwen-3-235b-think:free
  - model_name: workcode
    litellm_params:
      <<: *copilot_base
  - model_name: homesimple
    litellm_params:
      <<: *copilot_base
  - model_name: worksimple
    litellm_params:
      <<: *copilot_base
  - model_name: bge-reranker-base
    litellm_params:
      model: cohere/BAAI/bge-reranker-base
      api_base: http://localhost:5113
    model_info:
      id: local-bge-reranker-base


litellm_settings:
  callbacks: custom_litellm.proxy_handler_instance
  force_ipv4: true
  default_fallbacks: ["copilot-gpt-4.1"]

general_settings:
  #database_url: postgresql://postgres@localhost:5432/litellm
  store_model_in_db: false

router_settings:
  routing_strategy: simple-shuffle
  fallbacks: [
    {
      "homecode": [
        "deepseek-r1",
        "qwen3",
        "llama-4-maverick",
        "ollama/qwen3:8b" 
      ]
    },
    {
      "workcode": [
        "openrouter/anthropic/claude-sonnet-4-20250514",
        "anthropic/claude-sonnet-4-20250514",
        "openrouter/google/gemini-2.5-pro-preview",
        *copilot_default,
        "ollama/devstral" 
      ]
    },
    {
      "homesimple": [
        "llama-4-scout",
        "openrouter/google/gemma-3-27b-it:free",
        "ollama/gemma3:8b"
      ]
    },
    {
      "worksimple": [
        "llama-4-scout",
        "openrouter/google/gemma-3-27b-it",
        "ollama/gemma3:8b"
      ]
    },
    {
      "gpt-4.1": [
        "openrouter-gpt-4.1",
        "openai-gpt-4.1"
      ]
    },
    {
      "claude-3.7-sonnet": [
        "openrouter-claude-3.7-sonnet",
        "anthropic-claude-3.7-sonnet"
      ]
    },
    {
      "gemini-pro": [
        "openrouter-gemini-pro"
      ]
    },
    {
      "gemini-2.5-flash": [
        "openrouter-gemini-2.5-flash"
      ]
    },
    {
      "gemma-3": [
        "openrouter-gemma-3:27b",
        "cf-gemma-3:12b",
        "local-gemma-3:4b"
      ]
    },
    {
      "qwen3": [
        "cerebras-qwen-3-32b",
        "openrouter-qwen-3-32b"
      ]
    },
    {
      "qwen3big": [
        "openrouter-qwen-3-235b"
      ]
    },
    {
      "boron-embedding": [
        "local-embedding"
      ]
    }
  ]
  num_retries: 2

