common_copilot: &common_copilot
  api_base: https://api.githubcopilot.com
  api_key: "os.environ/COPILOT_API_KEY" 
  rpm: 15
  input_cost_per_token: 0.0
  output_cost_per_token: 0.0
  extra_headers:
    Copilot-Integration-Id: vscode-chat
    Editor-Version: neovim/0.11.1

claude_common: &claude_common
  max_output_tokens: 8192
  max_input_tokens: 90000
  mode: chat
  supports_vision: true
  supports_function_calling: true
  supports_parallel_function_calling: true
  supports_system_messages: true

copilot_claude37: &copilot_claude37
  model: openai/claude-3.7-sonnet
  max_tokens: 200000
  <<: [*claude_common, *common_copilot]

copilot_claude35: &copilot_claude35
  model: openai/claude-3.5-sonnet
  max_tokens: 90000
  <<: [*claude_common, *common_copilot]

copilot_geminipro: &copilot_geminipro
  model: openai/gemini-2.5-pro
  max_tokens: 90000
  max_output_tokens: 8192
  <<: *common_copilot

model_list:
  - model_name: ollama/*
    litellm_params:
      model: ollama_chat/*
      api_base: http://localhost:11434
  - model_name: boron/*
    litellm_params:
      model: ollama_chat/*
      api_base: http://10.0.0.10:11434
  - model_name: nitrogen/*
    litellm_params:
      model: ollama_chat/*
      api_base: http://10.0.0.11:11434
  - model_name: openai/*
    litellm_params:
      model: openai/*
  - model_name: groq/*
    litellm_params:
      model: groq/*
  - model_name: openrouter/*
    litellm_params:
      model: openrouter/*
  - model_name: anthropic/*
    litellm_params:
      model: anthropic/*
  - model_name: gemini/*
    litellm_params:
      model: gemini/*
  - model_name: github/*
    litellm_params:
      model: github/*
  - model_name: copilot/*
    litellm_params:
      model: openai/*
      <<: *common_copilot
  - model_name: hf/gemma-3-27b
    litellm_params:
      model: huggingface/nebius/google/gemma-3-27b-it
  - model_name: copilot/claude-3.7-sonnet
    litellm_params:
      <<: *copilot_claude37
  - model_name: copilot/claude-3.5-sonnet
    litellm_params:
      model: openai/claude-3.5-sonnet
      max_tokens: 90000
      <<: [*claude_common, *common_copilot]
  - model_name: gemini-pro
    litellm_params:
      <<: *copilot_geminipro
  - model_name: copilot/gemini-2.5-pro
    litellm_params:
      <<: *copilot_geminipro
  - model_name: copilot/gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      max_tokens: 128000
      max_output_tokens: 4096
      max_input_tokens: 64000
      <<: *common_copilot
  - model_name: copilot/gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      max_tokens: 128000
      max_output_tokens: 4096
      max_input_tokens: 64000
      <<: *common_copilot
  - model_name: boron-phi
    litellm_params:
      model: ollama_chat/hf.co/bartowski/microsoft_Phi-4-mini-instruct-GGUF:IQ4_XS
      api_base: http://10.0.0.10:11434
  - model_name: boron-gemma
    litellm_params:
      model: ollama_chat/hf.co/mradermacher/gemma-3-4b-it-i1-GGUF:Q4_K_S
      api_base: http://10.0.0.10:11434
  - model_name: boron-qwen
    litellm_params:
      model: ollama_chat/hf.co/bartowski/Qwen_Qwen3-4B-GGUF:IQ4_XS
      api_base: http://10.0.0.10:11434
  - model_name: boron-embedding
    litellm_params:
      model: ollama/granite-embedding:30m
      api_base: http://10.0.0.10:11434
  - model_name: local-embedding
    litellm_params:
      model: ollama/granite-embedding:30m
      api_base: http://localhost:11434
  - model_name: local-rerank
    litellm_params:
      model: ollama/hf.co/mradermacher/mxbai-rerank-large-v2-GGUF:Q4_K_M
      api_base: http://localhost:11434
  - model_name: boron-rerank
    litellm_params:
      model: ollama/hf.co/mradermacher/mxbai-rerank-large-v2-GGUF:Q4_K_M
      api_base: http://10.0.0.10:11434
  - model_name: homecode
    litellm_params:
      <<: *copilot_claude37
  - model_name: workcode
    litellm_params:
      <<: *copilot_claude37
  - model_name: homesimple
    litellm_params:
      model: openai/gemini-2.0-flash-001
      <<: *common_copilot
  - model_name: worksimple
    litellm_params:
      model: openai/gemini-2.0-flash-001
      <<: *common_copilot
  - model_name: homecodefast
    litellm_params:
      <<: *copilot_claude35
  - model_name: workcodefast
    litellm_params:
      <<: *copilot_claude35
router_settings:
  routing_strategy: simple-shuffle
  fallbacks: [
    {
      "homecode": [
        "copilot/gemini-2.5-pro",
        "openrouter/deepseek/deepseek-chat-v3-0324:free",
        "groq/meta-llama/llama-4-maverick-17b-128e-instruct",
        "gemini/gemini-2.5-pro-exp-03-25",
        "ollama/qwen3:8b" 
      ]
    },
    {
      "workcode": [
        "openrouter/anthropic/claude-3.7-sonnet",
        "anthropic/claude-3-7-sonnet-latest",
        "copilot/gemini-2.5-pro",
        "openrouter/google/gemini-2.5-pro-preview",
        "ollama/qwen3:8b" 
      ]
    },
    {
      "homesimple": [
        "groq/meta-llama/llama-4-scout-17b-16e-instruct",
        "openrouter/google/gemma-3-27b-it:free",
        "ollama/gemma3:8b"
      ]
    },
    {
      "worksimple": [
        "openrouter/google/gemma-3-27b-it",
        "groq/meta-llama/llama-4-scout-17b-16e-instruct",
        "ollama/gemma3:8b"
      ]
    },
    {
      "gemini-pro": [
        "openrouter/google/gemini-2.5-pro-preview"
      ]
    },
    {
      "boron-rerank": [
        "local-rerank"
      ]
    },
    {
      "boron-embedding": [
        "local-embedding"
      ]
    }
  ]
  num_retries: 3

