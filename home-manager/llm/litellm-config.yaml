copilot_default: &copilot_default copilot/gpt-4.1

common_copilot: &common_copilot
  api_base: https://api.githubcopilot.com
  api_key: "os.environ/COPILOT_API_KEY" 
  rpm: 15
  input_cost_per_token: 0.0
  output_cost_per_token: 0.0
  extra_headers:
    Copilot-Integration-Id: vscode-chat
    Editor-Version: neovim/0.11.1

claude_common: &claude_common
  max_output_tokens: 8192
  max_input_tokens: 90000
  mode: chat
  supports_vision: true
  supports_function_calling: true
  supports_parallel_function_calling: true
  supports_system_messages: true

copilot_claude4: &copilot_claude4
  model: openai/claude-sonnet-4
  max_tokens: 200000
  <<: [*claude_common, *common_copilot]

copilot_base: &copilot_base
  model: openai/gpt-4.1
  max_tokens: 128000
  max_output_tokens: 4096
  max_input_tokens: 64000
  <<: *common_copilot

copilot_claude37: &copilot_claude37
  model: openai/claude-3.7-sonnet
  max_tokens: 200000
  <<: [*claude_common, *common_copilot]

copilot_geminipro: &copilot_geminipro
  model: openai/gemini-2.5-pro
  max_tokens: 90000
  max_output_tokens: 8192
  <<: *common_copilot

litellm_settings:
  callbacks: custom_litellm.proxy_handler_instance

model_list:
  - model_name: ollama/*
    litellm_params:
      model: ollama_chat/*
      api_base: http://localhost:11434
  - model_name: boron/*
    litellm_params:
      model: ollama_chat/*
      api_base: http://10.0.0.10:11434
  - model_name: openai/*
    litellm_params:
      model: openai/*
  - model_name: openrouter/*
    litellm_params:
      model: openrouter/*
  - model_name: anthropic/*
    litellm_params:
      model: anthropic/*
  - model_name: gemini/*
    litellm_params:
      model: gemini/*
  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash-preview-05-20
  - model_name: gemmma-3
    litellm_params:
      model: gemini/gemma-3-27b-it
  - model_name: llama-4-scout
    litellm_params:
      model: groq/meta-llama/llama-4-scout-17b-16e-instruct
  - model_name: llama-4-scout
    litellm_params:
      model: cerebras/llama-4-scout-17b-16e-instruct
  - model_name: llama-4-scout
    litellm_params:
      model: cloudflare/@cf/meta/llama-4-scout-17b-16e-instruct
  - model_name: llama-4-scout
    litellm_params:
      model: openrouter/meta-llama/llama-4-scout:free
  - model_name: llama-4-maverick
    litellm_params:
      model: groq/meta-llama/llama-4-maverick-17b-128e-instruct
  - model_name: llama-4-maverick
    litellm_params:
      model: openrouter/llama-4-maverick:free
  - model_name: deepseek-r1-70b
    litellm_params:
      model: groq/deepseek-r1-distill-llama-70b
  - model_name: deepseek-r1-70b
    litellm_params:
      model: together_ai/deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free
  - model_name: codestral
    litellm_params:
      model: codestral/codestral-2501
  - model_name: codestral
    litellm_params:
      model: mistral/codestral-2501
  - model_name: mistral-medium
    litellm_params:
      model: mistral/mistral-medium-2505
  - model_name: mistral-small
    litellm_params:
      model: mistral/mistral-small-2503
  - model_name: mistral-small
    litellm_params:
      model: cloudflare/@cf/mistralai/mistral-small-3.1-24b-instruct
  - model_name: mistral-small
    litellm_params:
      model: openrouter/mistralai/mistral-small-3.1-24b-instruct:free
  - model_name: deepseek-r1
    litellm_params:
      model: openrouter/deepseek/deepseek-r1-0528
      temperature: 0.6
      top_p: 0.95
  - model_name: deepseek-r1-qwen3-8b
    litellm_params:
      model: openrouter/deepseek/deepseek-r1-0528-qwen3-8b:free
      temperature: 0.6
      top_p: 0.95
  - model_name: devstral
    litellm_params:
      model: mistral/devstral-small-2505
      weight: 10
  - model_name: devstral
    litellm_params:
      model: openrouter/mistralai/devstral-small:free
      weight: 5
  - model_name: devstral
    litellm_params:
      model: openrouter/mistralai/devstral-small:nitro
      weight: 3
  - model_name: devstral
    litellm_params:
      model: ollama/devstral
      weight: 1
  - model_name: gemma3:12b
    litellm_params:
      model: cloudflare/@cf/google/gemma-3-12b-it
  - model_name: llama-3.3
    litellm_params:
      model: cloudflare/@cf/meta/llama-3.3-70b-instruct-fp8-fast
  - model_name: llama-3.3
    litellm_params:
      model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free
  - model_name: llama-3.3
    litellm_params:
      model: groq/llama-3.3-70b-versatile
  - model_name: llama-3.3
    litellm_params:
      model: cerebras/llama-3.3-70b
  - model_name: llama-3.3
    litellm_params:
      model: openrouter/meta-llama/llama-3.3-70b-instruct:free
  - model_name: copilot/claude-4-sonnet
    litellm_params:
      <<: *copilot_claude4
  - model_name: copilot/claude-3.7-sonnet
    litellm_params:
      <<: *copilot_claude37
  - model_name: copilot/claude-3.5-sonnet
    litellm_params:
      model: openai/claude-3.5-sonnet
      max_tokens: 90000
      <<: [*claude_common, *common_copilot]
  - model_name: gemini-pro
    litellm_params:
      <<: *copilot_geminipro
  - model_name: copilot/gemini-2.5-pro
    litellm_params:
      <<: *copilot_geminipro
  - model_name: o3-mini
    litellm_params:
      model: openai/o3-mini
      weight: 20
      <<: *common_copilot
  - model_name: o4-mini
    litellm_params:
      model: openai/o4-mini
      weight: 20
      <<: *common_copilot
  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      # max_tokens: 128000
      # max_output_tokens: 8192
      # max_input_tokens: 64000
      weight: 20
      <<: *common_copilot
    model_info:
      id: copilot-gpt-4.1
  - model_name: gpt-4.1
    litellm_params:
      model: openrouter/openai/gpt-4.1
      weight: 2
      input_cost_per_token: 2e-06
      output_cost_per_token: 8e-06
    model_info:
      id: openrouter-gpt-4.1
  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      weight: 1
      input_cost_per_token: 2e-06
      output_cost_per_token: 8e-06
    model_info:
      id: openai-gpt-4.1
  - model_name: boron-phi
    litellm_params:
      model: ollama_chat/hf.co/bartowski/microsoft_Phi-4-mini-instruct-GGUF:IQ4_XS
      api_base: http://10.0.0.10:11434
  - model_name: boron-gemma
    litellm_params:
      model: ollama_chat/hf.co/mradermacher/gemma-3-4b-it-i1-GGUF:Q4_K_S
      api_base: http://10.0.0.10:11434
  - model_name: boron-qwen
    litellm_params:
      model: ollama_chat/hf.co/bartowski/Qwen_Qwen3-4B-GGUF:IQ4_XS
      api_base: http://10.0.0.10:11434
      temperature: 0.7
      top_p: 0.8
      top_k: 20
      min_p: 0
  - model_name: boron-code-embedding
    litellm_params:
      model: ollama/hf.co/gaianet/jina-embeddings-v2-base-code-GGUF:Q5_K_M
      api_base: http://10.0.0.10:11434
  - model_name: boron-embedding
    litellm_params:
      model: ollama/granite-embedding:30m
      api_base: http://10.0.0.10:11434
  - model_name: local-code-embedding
    litellm_params:
      model: ollama/hf.co/gaianet/jina-embeddings-v2-base-code-GGUF:Q5_K_M
      api_base: http://localhost:11434
  - model_name: local-embedding
    litellm_params:
      model: ollama/granite-embedding:30m
      api_base: http://localhost:11434
  - model_name: homecode
    litellm_params:
      #model: openrouter/deepseek/deepseek-chat-v3-0324:free
      model: openrouter/deepseek/deepseek-r1-0528:free
      temperature: 0.6
      top_p: 0.95
  - model_name: gemma3n
    litellm_params:
      model: openrouter/google/gemma-3n-e4b-it:free
  - model_name: qwen3
    litellm_params:
      model: openrouter/qwen/qwen3-32b:free
      #model: openrouter/qwen/qwen3-235b-a22b:free
      temperature: 0.7
      top_p: 0.8
      top_k: 20
      min_p: 0
      extra_body:
        reasoning:
          exclude: true
  - model_name: qwen3
    litellm_params:
      model: cerebras/qwen-3-32b
      #model: openrouter/qwen/qwen3-235b-a22b:free
      temperature: 0.7
      top_p: 0.8
      top_k: 20
      min_p: 0
  - model_name: qwen3big
    litellm_params:
      model: openrouter/qwen/qwen3-235b-a22b:free
      temperature: 0.7
      top_p: 0.8
      top_k: 20
      min_p: 0
      extra_body:
        reasoning:
          exclude: true
  - model_name: qwen3bigthink
    litellm_params:
      model: openrouter/qwen/qwen3-235b-a22b:free
      temperature: 0.6
      top_p: 0.95
      top_k: 20
      min_p: 0
  - model_name: workcode
    litellm_params:
      <<: *copilot_claude4
  - model_name: homesimple
    litellm_params:
      <<: *copilot_base
  - model_name: worksimple
    litellm_params:
      <<: *copilot_base
router_settings:
  routing_strategy: simple-shuffle
  fallbacks: [
    {
      "homecode": [
        "r1",
        "qwen3",
        *copilot_default,
        "llama-4-maverick",
        "ollama/qwen3:8b" 
      ]
    },
    {
      "workcode": [
        "openrouter/anthropic/claude-sonnet-4-20250514",
        "anthropic/claude-sonnet-4-20250514",
        "openrouter/google/gemini-2.5-pro-preview",
        *copilot_default,
        "ollama/devstral" 
      ]
    },
    {
      "homesimple": [
        "llama-4-scout",
        "openrouter/google/gemma-3-27b-it:free",
        "ollama/gemma3:8b"
      ]
    },
    {
      "worksimple": [
        "llama-4-scout",
        "openrouter/google/gemma-3-27b-it",
        "ollama/gemma3:8b"
      ]
    },
    {
      "gpt-4.1": [
        "openrouter-gpt-4.1",
        "openai-gpt-4.1"
      ]
    },
    {
      "gemini-pro": [
        "openrouter/google/gemini-2.5-pro-preview"
      ]
    },
    {
      "qwen3": [
        "openrouter/qwen/qwen3-235b-a22b"
      ]
    },
    {
      "boron-rerank": [
        "local-rerank"
      ]
    },
    {
      "boron-embedding": [
        "local-embedding"
      ]
    }
  ]
  num_retries: 3

